{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truck Vs Rig Network\n",
    "\n",
    "This network will classify a image of a truck or semi as a truck or a semi. \n",
    "\n",
    "## Why?\n",
    "\n",
    "This is my first project for fast.ai's v3 course. \n",
    "\n",
    "## Data?\n",
    "\n",
    "The data are images from the ImageNET dtaset, downloaded and cropped using a tool I created specifically to grab, crop, and scale images from the ImageNET dataset. For those who are interested, you can find out more about *grabber* [here](https://github.com/ScottVaverchak/ml-tools)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard dance. Set the notebook to reload extensions and show plots inline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.metrics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will import the data for training. Since these images are taken from the ImageNET dataset and I have no clue if I am allowed to share them or not, they will be excluded from this notbook. Below are the two URL's from ImageNET where you can find the images used to train the network:\n",
    "\n",
    " * [Semi Data Set](http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04467665)\n",
    " * [Pickup Data Set](http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n03930630)\n",
    " \n",
    "Once downloaded, cropped, and resized, the manual process starts. Many of the images form the ImageNET URL links no longer work or send down bad data. As of this writing (01/28/2019), the success rate of downloading was around 60%, which included bad data and non-images. Due to this, there is a bit of manual sorting to get bad data out of the directories.\n",
    "\n",
    "Once the sorting of bad data was compelete, I created a simple python script to move and rename the files into one directory. The structure looks like: \n",
    "\n",
    " - $cwd/images\n",
    "     - truck_0001.jpg\n",
    "     - truck_0002.jpg\n",
    "     - semi_0001.jpg\n",
    "     - semi_0002.jpg\n",
    "     - etc\n",
    "     \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
